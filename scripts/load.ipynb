{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zfwang/X2-GNN\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.chdir(os.path.abspath('../'))\n",
    "os.system('pwd')\n",
    "from xgnn import xgnn_poly, xgnn_poly_global, xgnn_poly_noattn\n",
    "from xgnn_equi import XGNN_Equi_force, XGNN_Equi\n",
    "import json\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from qm9_allprop import QM9_allprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "save_dir = os.path.abspath(\"./ckpt/HS_model\")\n",
    "ckpt_mark = \"U0\"\n",
    "bsz = 4\n",
    "\n",
    "ckpt_path = os.path.abspath(save_dir)\n",
    "ckpt = torch.load(os.path.join(ckpt_path, 'ckpt/ckpt_best.pth'))\n",
    "with open(f'{ckpt_path}/args.json','rt') as f:\n",
    "    args.update(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'attn' not in args:\n",
    "\targs['attn'] = True\n",
    "if 'include_H' not in args:\n",
    "\targs['include_H'],args['include_S'] = True, True\n",
    "if 'equi_model' not in args:\n",
    "\targs['equi_model'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=\"cuda\"\n",
    "if args['target'] in [5,6,7,8,9,10,11]:\n",
    "    if not args[\"equi_model\"]:\n",
    "        if not args[\"attn\"]:\n",
    "            model = xgnn_poly_noattn(include_H = args[\"include_H\"], include_S = args[\"include_S\"], conv_layers=args['conv_layers'], sbf_dim=args['sbf_dim'], rbf_dim=args['rbf_dim'], in_channels=args['in_channels'], heads=args['heads'], embedding_size=args['embedding_size'], device=device).to(device)\n",
    "        else:        \n",
    "            model = xgnn_poly(include_H = args[\"include_H\"], include_S = args[\"include_S\"], conv_layers=args['conv_layers'], sbf_dim=args['sbf_dim'], rbf_dim=args['rbf_dim'], in_channels=args['in_channels'], heads=args['heads'], embedding_size=args['embedding_size'], device=device).to(device)\n",
    "    else:\n",
    "        model = XGNN_Equi(conv_layers=args['conv_layers'], rbf_dim=args['rbf_dim'], vector_irreps=args['vector_irreps'], heads=args['heads'], hidden_dim = args['embedding_size'], device = device).to(device)\n",
    "else:\n",
    "    model = xgnn_poly_global(conv_layers=args['conv_layers'], sbf_dim=args['sbf_dim'], rbf_dim=args['rbf_dim'], in_channels=args['in_channels'], heads=args['heads'], embedding_size=args['embedding_size'], device=device, pool_option=args['pool_option']).to(device)   #model = Lora_xgnn_poly(conv_layers=args['conv_layers'], sbf_dim=args['sbf_dim'], rbf_dim=args['rbf_dim'], in_channels=args['in_channels'], heads=args['heads'], embedding_size=args['embedding_size'], rank=args['lora_rank'], device=device).to(device)\n",
    "ema_avg = lambda averaged_model_parameter, model_parameter:\\\n",
    "        args['ema_decay'] * averaged_model_parameter + (1-args['ema_decay']) * model_parameter\n",
    "ema_model = torch.optim.swa_utils.AveragedModel(model, avg_fn=ema_avg)\n",
    "\n",
    "model.load_state_dict(ckpt['model'], strict=False)\n",
    "ema_model.load_state_dict(ckpt['ema_model'], strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3686/1185384557.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t_preds = torch.tensor(preds).squeeze(-1)/0.04336414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# AID dataset\n",
    "dataset = QM9_allprop(input_file='./raw/AID_allprop.xyz')\n",
    "loader = DataLoader(dataset=dataset,batch_size=bsz)\n",
    "\n",
    "preds = torch.zeros(len(dataset))\n",
    "start = 0\n",
    "end = 0\n",
    "with torch.no_grad():\n",
    "    for data in loader:\n",
    "        data=data.to(device)\n",
    "        end += data.num_graphs\n",
    "        preds[start:end] = model(data).detach()\n",
    "        start += data.num_graphs\n",
    "torch.save(preds,f'./pickles/AID_{ckpt_mark}.pt')\n",
    "\n",
    "t_preds = torch.tensor(preds).squeeze(-1)/0.04336414\n",
    "delta = t_preds - dataset.data.y\n",
    "absolute = torch.abs(delta)\n",
    "\n",
    "atom_ref = np.array([np.nan, -0.500273, np.nan, np.nan, np.nan, np.nan,-37.84677172,-54.583861,-75.064579,-99.718730])\n",
    "\n",
    "from utils import read_xyz\n",
    "outputs = read_xyz('./raw/AID)allprop.xyz')\n",
    "\n",
    "Formula_list = []\n",
    "Heavy_Num = []\n",
    "sub_map = str.maketrans('0123456789', '₀₁₂₃₄₅₆₇₈₉')\n",
    "\n",
    "for i,mol in enumerate(outputs):\n",
    "    C_num = mol.Z.tolist().count(6)\n",
    "    ChemFor = f'C{C_num}'\n",
    "    H_num = mol.Z.tolist().count(1)\n",
    "    if H_num:\n",
    "        ChemFor += f'H{H_num}'\n",
    "    N_num = mol.Z.tolist().count(7)\n",
    "    if N_num:\n",
    "        ChemFor += f'N{N_num}'\n",
    "    O_num = mol.Z.tolist().count(8)\n",
    "    if O_num:\n",
    "        ChemFor += f'O{O_num}'\n",
    "    F_num = mol.Z.tolist().count(9)\n",
    "    if F_num:\n",
    "        ChemFor += f'F{F_num}'\n",
    "    Formula_list.append(ChemFor.translate(sub_map))\n",
    "    Heavy_Num.append(C_num+N_num+O_num+F_num)\n",
    "\n",
    "ids = range(len(dataset))\n",
    "\n",
    "import openpyxl\n",
    "wb=openpyxl.Workbook()\n",
    "ws=wb[\"Sheet\"]\n",
    "ws.cell(row = 1,column=1).value = 'id'\n",
    "ws.cell(row = 1,column=2).value = 'Fomula'\n",
    "ws.cell(row = 1,column=3).value = 'Heavy'\n",
    "ws.cell(row = 1,column=4).value = 'Total'\n",
    "ws.cell(row = 1, column = 5).value = 'Label'\n",
    "ws.cell(row = 1, column = 6).value = 'preds'\n",
    "ws.cell(row = 1, column = 7).value = 'delta'\n",
    "ws.cell(row = 1, column = 8).value = 'abs'\n",
    "ws.cell(row = 1, column = 9).value = 'per_heavy'\n",
    "ws.cell(row = 1, column = 10).value = 'per_atom'\n",
    "ws.cell(row = 1, column = 11).value = delta.mean().numpy().item()\n",
    "ws.cell(row = 1, column = 12).value = absolute.mean().numpy().item()\n",
    "for i in range(len(outputs)):\n",
    "    ws.cell(row=i+2,column=1).value = ids[i]\n",
    "    ws.cell(row=i+2,column=2).value = Formula_list[i]\n",
    "    ws.cell(row=i+2,column=3).value = Heavy_Num[i]\n",
    "    ws.cell(row=i+2,column=4).value = outputs[i].N.item()\n",
    "    ws.cell(row=i+2,column=5).value=dataset.data.y[i].numpy().item()\n",
    "    ws.cell(row=i+2,column=6).value=t_preds[i].numpy().item()\n",
    "    ws.cell(row = i+2, column = 7).value = delta[i].numpy().item()\n",
    "    ws.cell(row = i+2, column = 8).value = absolute[i].numpy().item()\n",
    "    ws.cell(row = i+2, column = 9).value = absolute[i].numpy().item()/Heavy_Num[i]\n",
    "    ws.cell(row = i+2, column = 10).value = absolute[i].numpy().item()/outputs[i].N.item()\n",
    "wb.save(f'./results_AID_{ckpt_mark}.xlsx')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCELOT dataset\n",
    "dataset = QM9_allprop(input_file='./raw/ocelot_all.xyz')\n",
    "loader = DataLoader(dataset=dataset,batch_size=bsz)\n",
    "\n",
    "preds = torch.zeros(len(dataset))\n",
    "start = 0\n",
    "end = 0\n",
    "with torch.no_grad():\n",
    "    for data in loader:\n",
    "        data=data.to(device)\n",
    "        end += data.num_graphs\n",
    "        preds[start:end] = model(data).detach()\n",
    "        start += data.num_graphs\n",
    "torch.save(preds,f'./pickles/ocelot_{ckpt_mark}.pt')\n",
    "\n",
    "t_preds = torch.tensor(preds).squeeze(-1)/0.04336414\n",
    "delta = t_preds - dataset.data.y\n",
    "absolute = torch.abs(delta)\n",
    "\n",
    "atom_ref = np.array([np.nan, -0.500273, np.nan, np.nan, np.nan, np.nan,-37.84677172,-54.583861,-75.064579,-99.718730])\n",
    "\n",
    "from utils import read_xyz\n",
    "outputs = read_xyz('./raw/ocelot_all.xyz')\n",
    "\n",
    "Formula_list = []\n",
    "Heavy_Num = []\n",
    "sub_map = str.maketrans('0123456789', '₀₁₂₃₄₅₆₇₈₉')\n",
    "\n",
    "for i,mol in enumerate(outputs):\n",
    "    C_num = mol.Z.tolist().count(6)\n",
    "    ChemFor = f'C{C_num}'\n",
    "    H_num = mol.Z.tolist().count(1)\n",
    "    if H_num:\n",
    "        ChemFor += f'H{H_num}'\n",
    "    N_num = mol.Z.tolist().count(7)\n",
    "    if N_num:\n",
    "        ChemFor += f'N{N_num}'\n",
    "    O_num = mol.Z.tolist().count(8)\n",
    "    if O_num:\n",
    "        ChemFor += f'O{O_num}'\n",
    "    F_num = mol.Z.tolist().count(9)\n",
    "    if F_num:\n",
    "        ChemFor += f'F{F_num}'\n",
    "    Formula_list.append(ChemFor.translate(sub_map))\n",
    "    Heavy_Num.append(C_num+N_num+O_num+F_num)\n",
    "\n",
    "ids = range(len(dataset))\n",
    "\n",
    "import openpyxl\n",
    "wb=openpyxl.Workbook()\n",
    "ws=wb[\"Sheet\"]\n",
    "ws.cell(row = 1,column=1).value = 'id'\n",
    "ws.cell(row = 1,column=2).value = 'Fomula'\n",
    "ws.cell(row = 1,column=3).value = 'Heavy'\n",
    "ws.cell(row = 1,column=4).value = 'Total'\n",
    "ws.cell(row = 1, column = 5).value = 'Label'\n",
    "ws.cell(row = 1, column = 6).value = 'preds'\n",
    "ws.cell(row = 1, column = 7).value = 'delta'\n",
    "ws.cell(row = 1, column = 8).value = 'abs'\n",
    "ws.cell(row = 1, column = 9).value = 'per_heavy'\n",
    "ws.cell(row = 1, column = 10).value = 'per_atom'\n",
    "ws.cell(row = 1, column = 11).value = delta.mean().numpy().item()\n",
    "ws.cell(row = 1, column = 12).value = absolute.mean().numpy().item()\n",
    "for i in range(len(outputs)):\n",
    "    ws.cell(row=i+2,column=1).value = ids[i]\n",
    "    ws.cell(row=i+2,column=2).value = Formula_list[i]\n",
    "    ws.cell(row=i+2,column=3).value = Heavy_Num[i]\n",
    "    ws.cell(row=i+2,column=4).value = outputs[i].N.item()\n",
    "    ws.cell(row=i+2,column=5).value=dataset.data.y[i].numpy().item()\n",
    "    ws.cell(row=i+2,column=6).value=t_preds[i].numpy().item()\n",
    "    ws.cell(row = i+2, column = 7).value = delta[i].numpy().item()\n",
    "    ws.cell(row = i+2, column = 8).value = absolute[i].numpy().item()\n",
    "    ws.cell(row = i+2, column = 9).value = absolute[i].numpy().item()/Heavy_Num[i]\n",
    "    ws.cell(row = i+2, column = 10).value = absolute[i].numpy().item()/outputs[i].N.item()\n",
    "wb.save(f'./results_ocelot_{ckpt_mark}.xlsx')\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo210",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
